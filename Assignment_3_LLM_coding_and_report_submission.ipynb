{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNgads4ovAbA0kR4hscIusc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f9404ecee0f74e4f8211fa20a656ee38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02d6aa7d653646859c0b108a3d68750c",
              "IPY_MODEL_072ceea2aaf548dc93c001430990000b",
              "IPY_MODEL_0c19ce9001254067a3928ef7c84aa4f0"
            ],
            "layout": "IPY_MODEL_a387675022a44975af3bc9291892f1b5"
          }
        },
        "02d6aa7d653646859c0b108a3d68750c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b5b2189305d422782514a19c7101c8d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d0ef140d40e04030b57c99915fbf8d60",
            "value": "Downloadingâ€‡builderâ€‡script:â€‡100%"
          }
        },
        "072ceea2aaf548dc93c001430990000b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f02b8b7346414543abb9fed6bdacb5f8",
            "max": 4203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6d56397fc7c443a8bd316beac971cd6",
            "value": 4203
          }
        },
        "0c19ce9001254067a3928ef7c84aa4f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d186f9a99564604abd7d2f634862b2b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_345f70a413304edcac41f56587762fe0",
            "value": "â€‡4.20k/4.20kâ€‡[00:00&lt;00:00,â€‡247kB/s]"
          }
        },
        "a387675022a44975af3bc9291892f1b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b5b2189305d422782514a19c7101c8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0ef140d40e04030b57c99915fbf8d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f02b8b7346414543abb9fed6bdacb5f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6d56397fc7c443a8bd316beac971cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d186f9a99564604abd7d2f634862b2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "345f70a413304edcac41f56587762fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UritiSrikanth/Assignment-3--LLM-coding-and-report-submission/blob/main/Assignment_3_LLM_coding_and_report_submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignment_3_LLM_coding_and_report_submission**"
      ],
      "metadata": {
        "id": "cd9Y_H96gcNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Link:** https://huggingface.co/datasets/fka/awesome-chatgpt-prompts\n",
        "\n",
        "**GitHub Link:** https://github.com/UritiSrikanth/Assignment-3--LLM-coding-and-report-submission\n"
      ],
      "metadata": {
        "id": "870rOyV5ggNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CODING PART:**"
      ],
      "metadata": {
        "id": "dbwp0Pa7jnS7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wf_1hjrktrxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03557410-7219-430f-89aa-870882dfdaea",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.5.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.15.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding, TrainerCallback\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "bYGcQx7jQZqA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We start by loading the dataset using the load_dataset function from the datasets library. In this case, we load the \"**fka/awesome-chatgpt-prompts**\" dataset, which contains columns 'act' and 'prompt'."
      ],
      "metadata": {
        "id": "sDHov2wfQg2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the dataset_prompts\n",
        "dataset_prompts = load_dataset(\"fka/awesome-chatgpt-prompts\")\n",
        "# Print the dataset structure\n",
        "print(\"dataset_prompts structure:\", dataset_prompts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdBf56VdQxDB",
        "outputId": "55a4bd15-ec74-4b73-da7f-16265d5917e3",
        "collapsed": true
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the latest cached version of the dataset since fka/awesome-chatgpt-prompts couldn't be found on the Hugging Face Hub\n",
            "WARNING:datasets.load:Using the latest cached version of the dataset since fka/awesome-chatgpt-prompts couldn't be found on the Hugging Face Hub\n",
            "Found the latest cached dataset configuration 'default' at /root/.cache/huggingface/datasets/fka___awesome-chatgpt-prompts/default/0.0.0/7baf3f8a5f3d38acc585d42d12193b27baf8cf79 (last modified on Tue Aug 13 14:38:46 2024).\n",
            "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'default' at /root/.cache/huggingface/datasets/fka___awesome-chatgpt-prompts/default/0.0.0/7baf3f8a5f3d38acc585d42d12193b27baf8cf79 (last modified on Tue Aug 13 14:38:46 2024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset_prompts structure: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['act', 'prompt'],\n",
            "        num_rows: 153\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first few entries to understand the data\n",
        "print(dataset_prompts['train'][:5])\n",
        "\n",
        "# Analyze the 'act' column to understand the distribution\n",
        "acts = [entry['act'] for entry in dataset_prompts['train']]\n",
        "unique_acts, counts = np.unique(acts, return_counts=True)\n",
        "\n",
        "# Create a dictionary of acts and their frequencies\n",
        "act_freq_dict = dict(zip(unique_acts, counts))\n"
      ],
      "metadata": {
        "id": "593fxoDEW46I",
        "outputId": "91fca1f2-17cb-4687-c018-c2da84655ef4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'act': ['Linux Terminal', 'English Translator and Improver', '`position` Interviewer', 'JavaScript Console', 'Excel Sheet'], 'prompt': ['I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd', 'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is \"istanbulu cok seviyom burada olmak cok guzel\"', 'I want you to act as an interviewer. I will be the candidate and you will ask me the interview questions for the `position` position. I want you to only reply as the interviewer. Do not write all the conservation at once. I want you to only do the interview with me. Ask me the questions and wait for my answers. Do not write explanations. Ask me the questions one by one like an interviewer does and wait for my answers. My first sentence is \"Hi\"', 'I want you to act as a javascript console. I will type commands and you will reply with what the javascript console should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is console.log(\"Hello World\");', \"I want you to act as a text based excel. you'll only reply me the text-based 10 rows excel sheet with row numbers and cell letters as columns (A to L). First column header should be empty to reference row number. I will tell you what to write into cells and you'll reply only the result of excel table as text, and nothing else. Do not write explanations. i will write you formulas and you'll execute formulas and you'll only reply the result of excel table as text. First, reply me the empty sheet.\"]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we use the BERT tokenizer from the transformers library to tokenize the '**prompt**' column. The tokenize_function is defined to apply padding and truncation to the tokenized outputs, ensuring that all sequences have the same length. We then map this tokenization function to the dataset using the map method, which processes the dataset in batches for efficiency."
      ],
      "metadata": {
        "id": "LcJl-7bOXbBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Tokenize the data\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['prompt'], padding=\"max_length\", truncation=True)\n",
        "\n",
        "processed_dataset_prompts = dataset_prompts.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "WVbqIieEXXhP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the dataset does not contain labels, we create a function add_labels that adds random binary labels **(0 or 1)** to each example. This simulates a classification problem, enabling us to train and evaluate the model. We map this function to the tokenized dataset, generating a labeled dataset. We use the DataCollatorWithPadding to create batches of data with uniform lengths, which is necessary for efficient training on the GPU. The tokenized dataset is then split into training and evaluation subsets using an 90-10 split, providing separate data for training and validation."
      ],
      "metadata": {
        "id": "SmyyztlxX9tR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Add dummy labels to the dataset_prompts (e.g., binary classification)\n",
        "import random\n",
        "\n",
        "def add_labels(examples):\n",
        "    examples['labels'] = [random.randint(0, 1) for _ in range(len(examples['prompt']))]\n",
        "    return examples\n",
        "\n",
        "processed_dataset_prompts = processed_dataset_prompts.map(add_labels, batched=True)\n",
        "\n",
        "# Prepare data for training\n",
        "sequence_data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Split dataset_prompts into training and evaluation\n",
        "processed_dataset_prompts = processed_dataset_prompts['train'].train_test_split(test_size=0.1)\n",
        "train_dataset_prompts = processed_dataset_prompts['train']\n",
        "eval_dataset_prompts = processed_dataset_prompts['test']"
      ],
      "metadata": {
        "id": "Lvkn6I4SZDi0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We initialize a BertForSequenceClassification model with two output labels, suitable for binary classification. We define TrainingArguments, specifying various training configurations like the output directory, evaluation strategy, logging settings, learning rate, batch sizes, number of epochs, and weight decay for regularization. We load the accuracy metric using the evaluate library and define the compute_metrics function to calculate accuracy from the model's predictions and the true labels. This function will be used during evaluation to track model performance. To log training and evaluation metrics, we create a custom MetricsCallback class that inherits from TrainerCallback. This class logs training loss, evaluation loss, training accuracy, and evaluation accuracy. The on_log method captures these metrics during training, and the on_epoch_end method computes training accuracy at the end of each epoch by iterating over the training dataloader and comparing predictions to true labels.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8LpHTnUVr-Z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Set up the Trainer\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTDeVkg0r5fP",
        "outputId": "a62e41bc-6930-4896-a182-55dcc2e51bf9",
        "collapsed": true
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the evaluation metric\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n"
      ],
      "metadata": {
        "id": "as2YBM-isKeT",
        "outputId": "3c058859-854c-439a-b95e-73b628d24e87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f9404ecee0f74e4f8211fa20a656ee38",
            "02d6aa7d653646859c0b108a3d68750c",
            "072ceea2aaf548dc93c001430990000b",
            "0c19ce9001254067a3928ef7c84aa4f0",
            "a387675022a44975af3bc9291892f1b5",
            "7b5b2189305d422782514a19c7101c8d",
            "d0ef140d40e04030b57c99915fbf8d60",
            "f02b8b7346414543abb9fed6bdacb5f8",
            "d6d56397fc7c443a8bd316beac971cd6",
            "3d186f9a99564604abd7d2f634862b2b",
            "345f70a413304edcac41f56587762fe0"
          ]
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9404ecee0f74e4f8211fa20a656ee38"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "    return accuracy_metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "N6ID79YqMRAe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MetricsCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.train_loss = []\n",
        "        self.eval_loss = []\n",
        "        self.train_acc = []\n",
        "        self.eval_acc = []\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs is not None:\n",
        "            if 'loss' in logs:\n",
        "                self.train_loss.append((state.global_step, logs['loss']))\n",
        "            if 'eval_loss' in logs:\n",
        "                self.eval_loss.append((state.global_step, logs['eval_loss']))\n",
        "            if 'eval_accuracy' in logs:\n",
        "                self.eval_acc.append((state.global_step, logs['eval_accuracy']))\n",
        "\n",
        "    def on_epoch_end(self, args, state, control, **kwargs):\n",
        "        train_dataloader = trainer.get_train_dataloader()\n",
        "        model.eval()\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "        for batch in train_dataloader:\n",
        "            inputs = {k: v.to(args.device) for k, v in batch.items()}\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            predictions = outputs.logits.argmax(dim=-1)\n",
        "            total_correct += (predictions == inputs['labels']).sum().item()\n",
        "            total_samples += predictions.size(0)\n",
        "        train_accuracy = total_correct / total_samples\n",
        "        self.train_acc.append((state.global_step, train_accuracy))\n"
      ],
      "metadata": {
        "id": "uul3kGgCsOyp"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_callback = MetricsCallback()\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset_prompts,\n",
        "    eval_dataset=eval_dataset_prompts,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=sequence_data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[metrics_callback],\n",
        ")"
      ],
      "metadata": {
        "id": "EppWyCHMshK1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "j8JQkuV7UYnG",
        "outputId": "1538fab3-5f54-4df2-85cf-327bcf7436a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:55, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.805422</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.743500</td>\n",
              "      <td>0.702645</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.666100</td>\n",
              "      <td>0.714033</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=27, training_loss=0.6872752684134024, metrics={'train_runtime': 58.4727, 'train_samples_per_second': 7.029, 'train_steps_per_second': 0.462, 'total_flos': 108138643752960.0, 'train_loss': 0.6872752684134024, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training, we evaluate the model on the validation set using trainer.evaluate(). This method returns the evaluation results, including validation loss and accuracy, which are printed out for review."
      ],
      "metadata": {
        "id": "am-8YUIxV7Q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Evaluate_the_model\n",
        "evaluation_summary = trainer.evaluate()\n",
        "\n",
        "# Print_evaluation_results\n",
        "print(\"Evaluation__results:\", evaluation_summary)"
      ],
      "metadata": {
        "id": "jgTyG7YgV9Nq",
        "outputId": "553c2a64-3cf0-402b-8a45-f804a3eea033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 01:25]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation__results: {'eval_loss': 0.7140331864356995, 'eval_accuracy': 0.6875, 'eval_runtime': 0.6224, 'eval_samples_per_second': 25.707, 'eval_steps_per_second': 1.607, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predictions**"
      ],
      "metadata": {
        "id": "01YTeTDJ8d8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Provided sentences\n",
        "sentences = [\n",
        "    \"I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd.\",\n",
        "    \"As a dietitian, I would like to design a vegetarian recipe for 2 people that has approximate 500 calories per serving and has a low glycemic index. Can you please provide a suggestion?\",\n",
        "    \"I want you to act a psychologist. i will provide you my thoughts. I want you to give me scientific suggestions that will make me feel better. my first thought, { typing here your thought, if you explain in more detail, i think you will get a more accurate answer.\",\n",
        "\n",
        "]\n",
        "\n",
        "# True labels (assuming these are the true labels for the provided sentences)\n",
        "true_labels = [\"command\", \"statement\", \"statement\"]\n",
        "\n",
        "# Tokenize the sentences\n",
        "tokenized_sentences = tokenizer(sentences, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Move tensors to the same device as the model\n",
        "input_ids = tokenized_sentences['input_ids'].to(model.device)\n",
        "attention_mask = tokenized_sentences['attention_mask'].to(model.device)\n",
        "\n",
        "# Predict with the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "    predictions = outputs.logits.argmax(dim=-1).cpu().numpy()\n",
        "\n",
        "# Map numeric predictions to labels\n",
        "label_mapping = {0: \"command\", 1: \"statement\", 2: \"question\"}\n",
        "predicted_labels = [label_mapping[pred] for pred in predictions]\n",
        "\n",
        "# Print the results\n",
        "for i, sentence in enumerate(sentences):\n",
        "    print(f\"Sentence {i+1}:\")\n",
        "    print(f\"Text: {sentence}\")\n",
        "    print(f\"True Label: {true_labels[i]}\")\n",
        "    print(f\"Predicted Label: {predicted_labels[i]}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "yIVu929Q3eeR",
        "outputId": "c6426b97-c5bf-4f3f-8360-b467e07b1570",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1:\n",
            "Text: I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd.\n",
            "True Label: command\n",
            "Predicted Label: command\n",
            "\n",
            "Sentence 2:\n",
            "Text: As a dietitian, I would like to design a vegetarian recipe for 2 people that has approximate 500 calories per serving and has a low glycemic index. Can you please provide a suggestion?\n",
            "True Label: statement\n",
            "Predicted Label: statement\n",
            "\n",
            "Sentence 3:\n",
            "Text: I want you to act a psychologist. i will provide you my thoughts. I want you to give me scientific suggestions that will make me feel better. my first thought, { typing here your thought, if you explain in more detail, i think you will get a more accurate answer.\n",
            "True Label: statement\n",
            "Predicted Label: command\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final_predictions**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3rCF7YiXPEFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map numeric predictions to labels\n",
        "label_mapping = {0: \"command\", 1: \"statement\", 2: \"question\"}\n",
        "predicted_labels = [label_mapping[pred] for pred in predictions]\n",
        "\n",
        "# Print raw logits, true labels, and predicted labels\n",
        "for i, sentence in enumerate(sentences):\n",
        "    print(f\"Sentence {i+1}:\")\n",
        "    print(f\"Text: {sentence}\")\n",
        "    print(f\"Logits: {logits[i].cpu().numpy()}\")  # Print raw logits\n",
        "    print(f\"True Label: {true_labels[i]}\")\n",
        "    print(f\"Predicted Label: {predicted_labels[i]}\")\n",
        "    print()\n",
        "\n",
        "# Check for any discrepancies in the label mapping\n",
        "print(\"Predictions:\", predictions)\n",
        "print(\"True Labels:\", true_labels)\n",
        "print(\"Predicted Labels:\", predicted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDRIYQtT8kV9",
        "outputId": "a44078a2-1abd-4242-957b-abef0e83b44b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1:\n",
            "Text: I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd.\n",
            "Logits: [0.3216548  0.08792661]\n",
            "True Label: command\n",
            "Predicted Label: command\n",
            "\n",
            "Sentence 2:\n",
            "Text: As a dietitian, I would like to design a vegetarian recipe for 2 people that has approximate 500 calories per serving and has a low glycemic index. Can you please provide a suggestion?\n",
            "Logits: [0.01182105 0.13202178]\n",
            "True Label: statement\n",
            "Predicted Label: statement\n",
            "\n",
            "Sentence 3:\n",
            "Text: I want you to act a psychologist. i will provide you my thoughts. I want you to give me scientific suggestions that will make me feel better. my first thought, { typing here your thought, if you explain in more detail, i think you will get a more accurate answer.\n",
            "Logits: [0.21048528 0.11228886]\n",
            "True Label: statement\n",
            "Predicted Label: command\n",
            "\n",
            "Predictions: [0 1 0]\n",
            "True Labels: ['command', 'statement', 'statement']\n",
            "Predicted Labels: ['command', 'statement', 'command']\n"
          ]
        }
      ]
    }
  ]
}